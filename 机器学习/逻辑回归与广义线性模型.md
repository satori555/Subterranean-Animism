# 逻辑回归与广义线性模型

## 逻辑回归（Logistic Regression）

考虑二分类任务, y 的取值只有 0 或 1，我们想把线性回归模型的预测值 z 转换为 0 或 1，例如单位阶跃函数，若 z>0 判为正例，若 z<0 判为反例。由于阶跃函数不连续，可以采用对数几率函数(logistic function)，也就是sigmoid函数：
$$
\begin{align}
y &= \frac1{1+e^{-z}} \\
  &= \frac1{1+e^{-w^Tx}}
\end{align}
$$
注意 x 和 w 可以是向量，偏置项 b 整合到参数 w 里面。

这时候 y 的取值在 0 到 1 之间。我们把 $\phi$ 视为 x 为正例的可能性 $p(y=1|x)$，则 $1-\phi$ 就是反例的可能性 $p(y=0|x)$，那么：
$$
p(y=1|x)\equiv \phi(x)=\frac1{1+e^{-w^Tx}}=\frac{e^{w^Tx}}{1+e^{w^Tx}} \\
p(y=0|x)\equiv 1-\phi(x)=\frac1{1+e^{w^Tx}}
$$


给定数据集$\{\vec{x}_i,y_i\}$，使用极大似然法来估计参数。似然函数为：
$$
\prod_{i=1}^N[\phi(x_i)]^{y_i}[1-\phi(x_i)]^{1-y_i}
$$
为了避免连乘，计算对数似然函数：
$$
\begin{align}
L(w) &=\sum_{i=1}^N[y_i\ln\phi(x_i)+(1-y_i)ln(1-\phi(x_i))] \\
&=\sum_{i=1}^N\left[ y_i\ln\frac{\phi(x_i)}{1-\phi(x_i)}+\ln(1-\phi(x_i)) \right] \\
&=\sum_{i=1}^N\left[ y_i(wx_i)-\ln(1+e^{(wx_i)}) \right]
\end{align}
$$
对 $L(w)$ 求极大值得到参数 $w$ 的估计。



## 广义线性模型

考虑线性回归模型：
$$
y = h(x) = w^Tx
$$
简单的线性模型有很多限制，比如 y 必须服从高斯分布，y 的范围是整个实数等。

具体来说有两个问题：

+ y 的取值范围和问题不匹配。例如 count （人数恒为正）以及 binary （二分类）
+ y 的方差是常数，但有些问题方差可能依赖 y 的均值，例如我预测目标值越大，方差也越大

我们可以用广义线性模型（Generalized Linear Model）来解决这两个问题。

要应用广义线性模型，响应变量 y 必须服从某个指数族分布：
$$
P(y;\eta)=b(y)\exp(\eta^T T(y)-a(\eta))
$$
其中，$\eta$ 被称为自然参数（natural parameters），$T(y)$ 被称为充分统计量（sufficient statistic），通常 $T(y)=y$ ，$a(\eta)$ 为正则化项。通过不同的 $a(\eta),b(y)$ 和 $T(y)$ 可将指数族分布转化为不同的概率分布。

例如，线性回归服从高斯分布，逻辑回归服从伯努利分布，此外还有多项分布，拉普拉斯分布，泊松分布等等。

广义线性模型的一个关键假设是：
$$
\eta=w^Tx
$$
即响应变量 y 相关的指数族分布的自然参数 $\eta$ 和变量 x 满足线性关系。

对于逻辑回归，设 y 服从伯努利分布，$\phi=p(y=1|x)$ ，
$$
\begin{align}
P(y;\phi)&=\phi^y(1-\phi)^{1-y} \\
&=\exp(y\ln\phi+(1-y)\ln(1-\phi)) \\
&=\exp\left[ y \left( \ln(\frac{\phi}{1-\phi}) \right) + \ln(1-\phi) \right]
\end{align}
$$
对比指数族分布的定义，有
$$
\begin{align}
b(y) &= 1 ,\quad T(y) = y \\
a(\eta) &= -\ln(1-\phi) = \ln(1+e^\eta) \\
\eta &= \ln(\frac{\phi}{1-\phi}) \equiv \text{logit}(\phi)
\end{align}
$$
根据自然参数 $\eta$ 的表达式，立刻得到逻辑回归模型 sigmoid 函数：
$$
\phi = \frac1{1+e^{-\eta}} = \frac1{1+e^{-w^Tx}}
$$


参考：

[1] 逻辑回归(logistics regression)_激进的蜗牛-CSDN博客
https://blog.csdn.net/weixin_39445556/article/details/83930186

[2] 机器学习面试之逻辑回归输出的值是真实的概率吗？ - 简书
https://www.jianshu.com/p/a8d6b40da0cf

[3] GLM(广义线性模型) 与 LR(逻辑回归) 详解_人工智能_段哥哥的博客-CSDN博客
https://blog.csdn.net/Cdd2xd/article/details/75635688?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

