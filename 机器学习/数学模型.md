# 机器学习常见的数学模型

## 线性回归

给定数据集(x, y)，用一个线性函数 $f(x_i)=wx_i+b$ 拟合，使得$f(x_i)\approx y_i$。

最小二乘法确定参数。

## 逻辑回归（对数几率回归）

考虑二分类任务，把线性回归模型的预测值z转换为0或1，例如单位阶跃函数，若z>0判为正例，若z<0判为反例。由于阶跃函数不连续，可以采用对数几率函数(logistic function)，也就是sigmoid函数：

为什么是sigmoid：

https://blog.csdn.net/weixin_39445556/article/details/83930186

https://blog.csdn.net/qq_19645269/article/details/79551576
$$
\begin{align}
y &= \frac1{1+e^{-z}} \\
  &= \frac1{1+e^{-w^Tx+b}}
\end{align}
$$
（注意x和w是向量）
$$
\ln\frac y{1-y} = w^Tx+b
$$
到这里函数y的意义还不清楚，我们可以自己定义（这会影响到计算w）。若将y视为x为正例的可能性$p(y=1|x)$，则1-y就是反例的可能性$p(y=0|x)$，那么
$$
\ln\frac{p(y=1|x)}{p(y=0|x)}=w^Tx+b
$$
定义对数几率(log odds，或logit)：
$$
\text{logit}(y)=\log\frac y{1-y}
$$
正例和反例的概率为：
$$
p(y=1|x)\equiv \pi(x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}} \\
p(y=0|x)\equiv 1-\pi(x)=\frac1{1+e^{w^Tx+b}}
$$


给定数据集$\{\vec{x}_i,y_i\}$，使用极大似然法来估计参数。似然函数为：
$$
\prod_{i=1}^N[\pi(x_i)]^{y_i}[1-\pi(x_i)]^{1-y_i}
$$
对数似然函数：
$$
\begin{align}
L(w) &=\sum_{i=1}^N[y_i\log\pi(x_i)+(1-y_i)log(1-\pi(x_i))] \\
&=\sum_{i=1}^N\left[ y_i\log\frac{\pi(x_i)}{1-\pi(x_i)}+\log(1-\pi(x_i)) \right] \\
&=\sum_{i=1}^N\left[ y_i(wx_i+b)-\log(1+e^{(wx_i+b)}) \right]
\end{align}
$$
其中$wx_i\equiv\sum_j w_jxji$

对$L(w)$求极大值得到$w$的估计值。



## 支持向量机

## 朴素贝叶斯分类器

## AdaBoost



