# 机器学习 周志华

## 1. 绪论

什么是机器学习？

一些术语：

数据集，样本（实例），属性（特征），特征向量，维数。训练样本，测试样本，训练集，测试集。泛化能力。分类，回归。监督学习，无监督学习。

## 2. 模型评估与选择

​     误差，过拟合，欠拟合。

​     评估方法：划分训练集与测试集。1留出法：将数据集划分成两个，一个作为训练集一个作为测试集。采用若干次划分，重复取平均值。2交叉验证法：将数据集划分成k个子集，依次用k-1个子集训练，余下的一个做为测试集。（留一法：每个子集只有一个样本）。3自助法：给定包含m个样本的数据集D，每次挑一个样本拷贝再放回，重复m次，始终没有被采样到的作为测试集。数据集较小时常用。

​     性能度量：均方误差（MSE），查准率/查全率/F1，ROC/AUC，代价敏感错误率与代价曲线。

​     查准率P=真正例/（真正例+假正例），查全率（召回率）R=真正例/（真正例+假反例）。二者相互矛盾。PR曲线：两个学习器PR曲线下面积大的性能更优，或者平衡点（R=P）越高越优。F1度量：比平衡点更常用。F1=2PR/（P+R）。一般形式Fβ。F1越高越好。

  ROC（受试者工作特征）：横轴假正例率，纵轴真正例率。ROC偏重研究基于测试样本评估值的排序好坏。AUC越大，证明排序的质量越好，AUC为1时，证明所有正例排在了负例的前面，AUC为0时，所有的负例排在了正例的前面。

​     代价敏感错误率：为错误赋予权重。

​     比较检验：若A在某测试集上的性能优于B，那A学习器比B好的把握有多大。

​     偏差与方差：偏差体现了学习器预测的准确度，而方差体现了学习器预测的稳定性。随着训练程度提升，偏差越来越小，方差越来越大。

## 3. 线性模型

​     线性模型试图学得一个通过属性的线性组合进行预测的函数：f(x)=w*x+b。

​     线性回归：学得一个线性模型尽可能准确地预测新样本的输出值。

​     对数线性回归：ln y = w*x+b。

​     对数机率回归（逻辑回归）：将预测值投影到0-1之间，二分类问题。

​     线性判别分析（LDA）：将训练样本投影到直线上，同类尽量近，不同类尽量远。

​     多分类学习：一对一OvO（N个分类两两配对，投票产生结果），一对余OvR（每次取出一个类别作为正类，产生N个二分类学习器。测试阶段得出N个结果，若仅有一个学习器预测为正类，则为最终分类结果），多对多MvM（每次取若干个正类，若干个反类。纠错输出码ECOC）。

​     类别不平衡问题（不同类别训练样本相差悬殊）：1较多样本中欠采样，2较少样本过采样（插值），3基于原数据集学习，对预测值再缩放处理（代价敏感学习）。

## 4. 决策树

​     决策树构造：1当前节点包含的样本属于同一类别，标记为叶节点。2当前属性集为空，或样本在各属性上取值相同无法划分，则标记为叶节点，类别设为该节点所含样本最多的类别。3当前节点包含的样本集合为空，无法划分，则标为叶节点，类别设为父节点中包含样本最多的类别。

​     划分属性的方法（划分出的节点尽可能纯，即属于同一类别）：ID3，C4.5，CART。

​     ID3：选择信息增益最大的属性作为当前的划分属性。偏向于取值数目较多的属性。

Gain(D,a)=Ent(D)-求和{(Dv/D)Ent(Dv)}

​     C4.5：选择增益率最大的属性。Gain_rate(D,a)=Gain(D,a)/IV(a)，IV(a)=-求和(Dv/D)log(Dv/D)，属性a取值越多，IV(a)越大。

​     CART算法：基尼系数：从样本集D中随机抽两个样本，标记不一样的概率，越小越好。

Gini(D)=1-求和pk平方。

​     剪枝处理：过拟合。预剪枝（容易欠拟合），后剪枝（性能好时间长）。

​     连续值：二分法离散化，选信息增益最大的划分点。

​     缺失值。1划分属性：在样本集中选属性a上没有缺失值的子集，计算信息增益，乘以无缺失样本的比重。2如何划分：若该样本子集在属性a上的值缺失，则将该样本以不同的权重划入到所有分支节点中。

 

## 5. 神经网络

​     感知机：一层神经元，dwi=\eta(y-y’)xi

​     误差逆传播（BP）算法：链式法则。过拟合：早停（若训练集积累误差降低而测试集误差升高，则停止），正则化（在积累误差函数中增加一个描述网络复杂度的部分，常通过交叉验证法来估计）。

​     深度学习：BP算法容易发散。无监督逐层训练，权共享。

 

## 6. 支持向量机SVM

​     线性二分类，目标是间隔最大化。超平面：wTx+b=0，w，x是向量。

​     函数间隔（wx+b的绝对值）与几何间隔（点到超平面的距离）。

​     对偶问题：求|w|平方的最小值。对偶问题容易求解，向量内积形式引出核函数。

​     拉格朗日乘子法，KKT条件。SMO算法（每次选择两个变量固定其他参数）。

​     核函数：解决线性不可分的问题。学习与预测中只定义核函数K，而不显式地定义映射函数。

​     常用的核函数：线性核（线性可分的情况），多项式核，高斯核。

​     软间隔SVM：允许某些数据不满足约束，同时使不满足约束的数据尽可能少。

​     损失函数：0/1损失，hinge损失，指数损失，对率损失。

 

## 7. 贝叶斯分类器

​     假设在相关概率都已知的情况下，贝叶斯分类器考虑如何基于这些概率为样本判定最优的类标。

​     贝叶斯公式。

​     贝叶斯决策论：为最小化总体风险，在每个样本上选择那个使得条件风险最小的类标。对于每个样本x，后验概率P(c|x)最大的类标c能使总体风险最小。

​     估计后验概率：判别式模型（决策树，神经网络，SVM）直接对P(c|x)建模求解。生成式模型（贝叶斯分类器）：通过对联合分布P(c,x)建模，进一步求解P(c|x)。

​     极大似然法：写出对数似然函数log P(D|θ)，对θ求导令似然极大。效果非常依赖于所假设的概率分布是否符合真实数据分布。

​     朴素贝叶斯分类器：属性条件独立假设。平滑方法。

​     半朴素贝叶斯分类器。贝叶斯网。

EM算法。

 

## 8. 集成学习

​     同质集成：个体学习器称为“基学习器”（base learner），对应的学习算法为“基学习算法”（base learning algorithm）。 异质集成：个体学习器称为“组件学习器”（component learner）或直称为“个体学习器”。

​     要获得好的集成，个体学习器应好而不同：准确性，多样性。

​     Boosting：串行工作，学习器的训练存在依赖关系。增加前一个基学习器预测错误的样本的权重，向下串行直到产生需要的T个学习器，最终加权结合。AdaBoost使用指数损失函数，算法：1初始化权值分布。2训练弱分类器，错误的样本权值增加。3结合成强分类器，加大误差率小的弱分类器的权重，降低误差大的权重。更新权重的方法：重赋权法，重采样法。

​     Bagging：使用T次自助法训练出T个学习器进行组合。集学习器为神经网络与决策树等对训练集敏感的不稳定学习算法，降低方差。

​     随机森林（RF）：Bagging的一个拓展，基学习器为决策树。使用自助法（样本扰动）同时引入属性扰动（划分属性时先随机选出包含K个属性的子集，推荐K=log d），进一步提升基学习器的差异度。

​     结合策略：平均法（回归问题，个体学习器差异小-简单，差异大-加权），投票法（分类问题，绝对多数，相对多数，加权投票），学习法（学习出一种投票，Stacking）。

​     多样性：数据样本扰动，输入属性扰动，输出表示扰动，算法参数扰动。

 

## 9. 聚类

​     如何度量相似性：距离度量，性能度量（评价聚类结果好坏）。

​     距离度量：闵可夫斯基距离。P=1即曼哈顿距离，P=2即欧氏距离。

​    连续属性可以直接被学习器使用，有序属性可以转化为连续属性，无序属性可以采用VDM（value difference metric）。

​     性能度量：外部指标（与参考模型比较），内部指标（簇内距离尽量小，簇间距离尽量大）。

​     原型聚类：K-means聚类，学习向量化（LVQ），高斯混合聚类

​     密度聚类：ε-邻域，核心对象，密度直达，密度可达，密度相连。

​     层次聚类：单链接，全链接，均链接。

 

## 10. 降维与度量学习

​     K近邻学习（KNN）：给定测试样本，找出训练集中最近的K个样本预测（投票法）。

​     低维嵌入：数据样本是高维的，但与学习任务密切相关的只是某低维分布，即高维空间中的一个低维嵌入。

​     MDS（多维缩放）算法：要求原始空间中样本的距离在低维空间中保持。

​     主成分分析（PCA）：通过一个线性变换，将原始空间中的样本投影到新的低维空间中。简单来理解这一过程便是：PCA采用一组新的基来表示样本点，其中每一个基向量都是原来基向量的线性组合，通过使用尽可能少的新基向量来表出样本，从而达到降维的目的。

​     最近重构性：样本点到超平面的距离足够近，即尽可能在超平面附近； 最大可分性：样本点在超平面上的投影尽可能地分散开来，即投影后的坐标具有区分性。

​     核化线性降维：非线性可分。核化PCA。

​     流形学习。

​     度量学习：学习距离度量。各个属性有权重，有关联。马氏距离。

## 11. 特征选择与稀疏学习

​     特征选择：从给定的特征集合中选出相关特征子集。

​     子集搜索，子集评价，用贪心算法，与ID3决策树类似。

​     过滤式选择。Relief算法：使用“相关统计量”来度量特征的重要性，每个分量代表着相应特征的重要性。猜对近邻距离最小，猜错近邻距离最大。

​     包裹式选择：训练学习器，计算开销大。

​     蒙特卡罗算法：采样越多，越近似最优解，一定会给出解，但给出的解不一定是正确解（找最大的苹果）； 拉斯维加斯算法：采样越多，越有机会找到最优解，不一定会给出解，且给出的解一定是正确解（找能开锁的钥匙）。

​     LVW算法：在拉斯维加斯算法框架下使用随机策略来进行特征子集的搜索。

​     嵌入式选择与正则化：在学习器训练过程中自动进行了特征选择。L2范数正则化：降低过拟合风险。L1范数正则化：会使部分w变成0，减少特征数目。

​     稀疏编码/字典学习：将稠密数据集转化为稀疏表示。

​     压缩感知：根据部分信息恢复全部信息，前提是信息具有稀疏表示。

## 12. 计算学习理论

​     分析学习任务的本质：在什么条件下可进行有效的学习，需要多少训练样本能获得较好的精度等，从而为机器学习算法提供理论保证。

## 13. 半监督学习

​     未标记样本。主动学习（本质上是监督学习），纯半监督学习，直推学习。

​     半监督学习：让学习过程不依赖外界的咨询交互，自动利用未标记样本提升学习性能。

​     生成式方法：假定样本数据服从一个潜在的分布，因此需要充分可靠的先验知识。例如：贝叶斯分类器+高斯混合聚类。

​     半监督SVM。S3VM：考虑未标记样本后，试图找到能分开有标记样本且穿过数据低密度区域的划分超平面。TSVM：先利用有标记样本学习一个SVM，然后标记未标记样本，找出易错样本重新划分，迭代求解。

​     图半监督学习。

​     基于分歧的方法。

​     半监督聚类。

## 14. 概率图模型

​     概率图模型：用图结构来表达各属性之间关系。结点表示随机变量，边表示变量间的关系。有向图模型：贝叶斯网。无向图模型：马尔可夫网。

​     隐马尔可夫模型（HMM）：观测变量的取值仅依赖于状态变量；下一个状态的取值仅依赖于当前状态。状态一般是未知的（隐变量）。

​     三个参数：状态转移概率，输出观测概率，初试状态概率。

​     产生观测序列：1生产初始状态，2产生观测值，3确定转移后的状态，4循环。

​     三个问题：1给定模型计算产生观测序列x的概率（评估模型和观测序列的匹配程度），如给定x1-xn-1推测xn。2给定模型和观测序列x，推断隐藏的状态，如语音识别根据语音信号推断文字。3给定观测序列，如何调整参数使该序列出现的概率最大？如何训练样本学得最优的模型参数。

​     全局马尔可夫性：给定两个变量子集的分离集，则这两个变量子集条件独立。

​     推论：全局马尔可夫性，成对马尔可夫性。

​     条件随机场CRF。判别式模型，给定观测序列后对状态的概率建模。

​     学习与推断：从联合概率得到边际分布。

​     变量消去：调整求和求积的顺序简化计算。缺点：求解多个边缘分布时重复计算。

​     信念传播：一个节点在接收到所有其它节点的消息后才向另一个节点发送消息，同时当前节点的边际概率正比于他所接收的消息的乘积。

​     隐狄利克雷分配（LDA）模型：推断给定文档所蕴含的话题分布。

## 15. 规则学习

## 16. 强化学习

​     强化学习通过反馈的结果信息不断调整之前的策略，从而算法能够学习到：在什么样的状态下选择什么样的动作可以获得最好的结果。

​     马尔可夫决策过程：机器处在一个环境中，每个状态为机器对当前环境的感知；机器只能通过动作来影响环境，当机器执行一个动作后，会使得环境按某种概率转移到另一个状态；同时，环境会根据潜在的奖赏函数反馈给机器一个奖赏。

​     强化学习四要素：状态、动作、转移概率以及奖赏函数。

状态（X）：机器对环境的感知，所有可能的状态称为状态空间； 动作（A）：机器所采取的动作，所有能采取的动作构成动作空间； 转移概率（P）：当执行某个动作后，当前状态会以某种概率转移到另一个状态； 奖赏函数（R）：在状态转移的同时，环境给反馈给机器一个奖赏。

​     K-摇臂赌博机。仅探索法，仅利用法。两者折中。

​     ε-贪心法：以ε的概率进行探索，即以均匀概率随机选择一个动作；以1-ε的概率进行利用，即选择当前最优的动作。

​     Softmax算法：Softmax函数将一组值转化为一组概率，值越大对应的概率也越高，因此当前平均奖赏值越高的动作被选中的几率也越大。