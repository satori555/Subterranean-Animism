# 高斯过程与贝叶斯优化

### 随机过程

随机过程——维纳过程 - MwingFly - 博客园
https://www.cnblogs.com/zhangzefei/p/9926044.html

泊松过程

马尔可夫过程

### 高斯过程

高斯过程指的是一组随机变量的集合，这个集合里面的任意有限个随机变量都服从联合正态分布，记作
$$
\mathcal{GP}(\mu,\Sigma)
$$
其中：
$$
\begin{matrix}
\mu(t)=E(X_t), & t\in T \\
\Sigma(t_1,t_2)=\kappa(X_{t_1},X_{t_2}), & t_1,t_2\in T
\end{matrix}
$$
高斯过程的性质与其协方差函数有密切联系，在构造高斯过程时，一些特定形式的协方差函数被称为核函数。



### 高斯过程回归

##### 回归模型：

$$
y=f(X)+\epsilon
$$

其中 $\epsilon$ 为残差或噪声，假设其服从独立同分布（iid）的0均值正态分布：$p(\epsilon)=N(\epsilon|0,\sigma^2_n)$ . 

GPR取 $f(X)$ 的先验为 0 均值高斯过程：
$$
f(X)\sim\mathcal{GP}[0,\kappa(X,X')]
$$

其中 $X$ 为学习样本。由高斯过程的定义：
$$
\forall t\in\mathbb{N}, X=\{X_1,...,X_t\}\in\mathbb{R_d}:
\mathbb{P}[f(X_1),...f(X_t)]\sim N[0,\kappa(X,X')]
$$
其中 $\kappa$ 为核函数：
$$
\kappa(X,X')=\mathbb{E}[f(X)f(X')]
$$
给定学习样本，GPR在高斯过程先验和正态分布似然下求解回归模型的后验：
$$
p[f(X)|f(X_1),...,f(X_N)]
$$
并对测试样本的结果进行估计。由定义：
$$
y\sim N(0,K+\sigma^2_nI),\quad f_*\sim N[0,\kappa(X_*,X_*)]
$$
二者的联合概率分布为：
$$
\left[\begin{matrix} y\\f_* \end{matrix}\right]
\sim
N\left(0,
\left[\begin{matrix}
K(X,X)+\sigma^2_nI & K(X,X_*) \\
K(X_*,X) & \kappa(X_*,X_*)
\end{matrix}\right]
\right)
$$
对上述联合分布取 $f_*$ 的边缘分布，可得：
$$
p(f_*|X,y,X_*,\sigma^2_n)=N[f_*|\overline{f_*},\text{cov}(f_*)] \\
\overline{f_*}=k(X_*,X)(K+\sigma^2_nI)^{-1}y  \\
\text{cov}(f_*)=\kappa(X_*,X_*)-k(X_*,X)(K+\sigma^2_nI)^{-1}k(X,X_*)
$$
上式是GPR的预测形式。



##### 极大似然估计：

GPR的求解是按贝叶斯方法通过学习样本确定超参数的过程。由贝叶斯定理：
$$
p(\theta|X,y)=\frac{p(y|X,\theta)p(\theta)}{p(y|X)}
$$
其中 $\theta$ 为GPR的超参数，包括核函数的超参数和残差的方差 $\sigma^2_n$ 。

似然 $p(y|X,\theta)=N(y|0,K+\sigma^2_nI)$ ，代入联合正态分布并求负对数可得：
$$
-\log p(y|X,\theta)=y^\top (K+\sigma^2_nI)^{-1}y
+\frac12\log|K+\sigma^2_nI|
+\frac n2\log{2\pi}
$$
可以通过非线性优化算法求解。

GPR的优化复杂度随学习样本的增加而增大。



### 贝叶斯优化

