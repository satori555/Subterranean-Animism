# 集成学习

## AdaBoost (Adaptive Boosting)

对提升方法来说，有两个问题需要回答：

1. 在每一轮如何改变训练数据的权值或概率分布？

   AdaBoost：提高那些被前一轮分类器错误分类的样本的权值，降低被正确分类的样本的权值。

2. 如何将弱分类器组合成一个强分类器？

   AdaBoost：加权多数表决，即加大分类错误率小的弱分类器的权值，减小分类错误率大的弱分类器的权值。

AdaBoost训练过程：

数据集 $T=(x_i,y_i)$ ，其中 $y_i=\pm1$ ，输出最终分类器 $G(x)$。

+ 初始化训练数据集的权值为均匀分布 $D_1$ 

+ 对 m = 1, 2, ..., M：
  
  + 使用具有权值分布的训练集学习，得到基本分类器 $G_m$ 
  
  + 计算 $G_m(x)$ 在训练数据集上的分类误差率 $e_m$ 
  
  + 计算 $G_m(x)$ 的系数
    $$
    \alpha_m=\frac12\ln\frac{1-e_m}{e_m}
    $$
  
  + 更新训练集的权值分布（$Z_m$ 为归一化因子）
    $$
    D_{m+1}=(w_{m+1,1},w_{m+1,2},...,w_{m+1,N})
    $$
  
    $$
    w_{m+1,i}=\frac{w_{mi}}{Z_m}\exp(-\alpha_my_iG_m(x_i)),\ i=1,2,...,N
    $$
  
+ 组合得到最终分类器

  $$
  G(x)=\text{sign} \left( \sum_{m=1}^M \alpha_m G_m(x) \right)
  $$

由前向分步算法可以推导出 AdaBoost：
$$
f_m(x)=f_{m-1}(x)+\alpha_m G_m(x)
$$
目标函数使用指数损失：
$$
(\alpha_m,G_m(x))
= \arg\min_{\alpha,G} \sum_i \exp[-y_i(f_{m-1}(x)+\alpha G(x_i))]
$$
注意到 $f_{m-1}$ 和 当前 $m$ 轮训练无关：
$$
\begin{align}
\sum_i\exp[y_i\alpha G(x)]
&= \sum_{y_i=G_m(x_i)}e^{-\alpha}+\sum_{y_i\ne G_m(x_i)}e^{\alpha} \\
&= (1-e_m)e^{-\alpha} + e_me^{\alpha}
\end{align}
$$
为了使损失函数最小，对 $\alpha$ 求导并使导数为 0 ：
$$
-(1-e_m)e^{-\alpha} + e_me^{\alpha} = 0
$$
得：
$$
\alpha_m = \frac12\ln\frac{1-e_m}{e_m}
$$

## 随机森林

随机森林中由许多分类树，如果要将一个输入样本进行分类，我们需要将输入样本输入到每棵树中进行分类，最后投票决定结果。

生成决策树：

+ 设训练集大小为 N，对每棵树随机有放回地抽取 N 个训练样本（bootstrap sampling），作为该树的训练集。
  + 为什么要随机抽样？如果每棵树的训练集都一样，那么最终训练出的树分类结果也是一样的，没有 bagging 的必要。
  + 为什么要有放回抽样？如果每棵树的训练样本都没有交集，每棵树都有很大的差异。随机森林最后分类取决于多棵树的投票表决，即 “求同”，因此每棵树的训练样本应该存在交集。
+ 如果每个样本的特征维度为 M，指定一个常数 m<<M，随机地从 M 个特征中选取 m 个特征，每次分裂节点时，从这 m 个特征中选最优的。
+ 每棵树都尽最大可能生长，并且没有剪枝。

随机森林分类效果（错误率）与两个因素有关：

+ 森林中任意两棵树的相关性：相关性越大，错误率越大。
+ 森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。

这两个因素是互相矛盾的。减少特征数 m，树的相关性和分类能力也会降低，增大 m 两者也会随之增大。关键问题是如何选择最优的 m （或范围），这也是随机森林唯一的一个参数。

## 偏差与方差

Boosting 是迭代算法，每次迭代都根据上一次的预测结果对样本进行权重调整，随着迭代不断进行，偏差会越来越小。

Bagging 对训练样本采样产生若干不同的子集，对每个子集训练一个基分类器，这些集分类器的期望近似于整体模型的期望。综合多个基分类器的结果，结果是降低了模型的方差。



##### 参考：

[1] 李航，统计学习方法

[2] 【机器学习】 随机森林（Random Forest）_人工智能_云峰阁-CSDN博客
https://blog.csdn.net/qq_34106574/article/details/82016442