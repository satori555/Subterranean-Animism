# 机器学习常用的数学推导

## 线性回归

给定数据集(x, y)，用一个线性函数 $f(x_i)=wx_i+b$ 拟合，使得$f(x_i)\approx y_i$。

最小二乘法

## 逻辑回归（对数几率回归）

考虑二分类任务，把线性回归模型的预测值z转换为0或1，例如单位阶跃函数，若z>0判为正例，若z<0判为反例。由于阶跃函数不连续，可以采用对数几率函数(logistic function):
$$
\begin{align}
y &= \frac1{1+e^{-z}} \\
  &= \frac1{1+e^{-w^Tx+b}}
\end{align}
$$
（注意x和w是向量）
$$
\ln\frac y{1-y} = w^Tx+b
$$
到这里函数y的意义还不清楚，我们可以自己定义（这会影响到计算w）。若将y视为x为正例的可能性$p(y=1|x)$，则1-y就是反例的可能性$p(y=0|x)$，那么
$$
\ln\frac{p(y=1|x)}{p(y=0|x)}=w^Tx+b
$$
(李航 统计学习方法，补充)



## BP神经网络

## 支持向量机

## 朴素贝叶斯分类器

## EM算法

## AdaBoost

## 树模型

决策树

xgboost

随机森林



