# 隐马尔可夫模型

**定义：**隐马尔科夫模型（Hidden Markov Model, HMM）是可用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。

HMM 由初始概率分布 $\pi=(\pi_i)$、状态转移概率分布 $A=[a_{ij}]$ 以及观测概率分布 $B=[b_j(k)]$ 确定：
$$
\lambda=(A,B,\pi)
$$
其中，$a_{ij}$ 表示状态 $i$ 在下一时刻转移到状态 $j$ 的概率 ，$b_j(k)$ 表示状态 $j$ 生成观测 $k$ 的概率，$\pi_i$ 表示初始时刻处于状态 $i$ 的概率。

**基本假设：**

+ 齐次马尔可夫性：任意时刻的状态只依赖于前一时刻的状态。
+ 观测独立性：任意时刻的观测只依赖于该时刻的状态。



**三个基本问题：**概率计算问题，学习问题，预测问题。

**概率计算问题**

给定模型 $\lambda=(A,B,\pi)$ 和观测序列 $O(o_1,o_2,...,o_T)$ ，计算模型 $\lambda$ 下观测序列 $O$ 出现的概率 $P(O|\lambda)$ 。

1. 直接计算法：最直接的方法是列举所有可能长度为 T 的状态序列，计算联合概率，计算量太大。

2. 前向算法：定义到 $t$ 时刻部分观测序列为 $o_1\sim o_t$ 且状态为 $q_i$ 的概率为 **前向概率** ：
   $$
   \alpha_t(i)=P(o_1,...o_t,i_t=q_i|\lambda)
   $$
   初始化前向概率：
   $$
   \alpha_1(i)=\pi_ib_i(o_1)
   $$
   递推，$t = 1,...,T-1$：
   $$
   \alpha_{t+1}(i)=\left[ \sum_j\alpha_t(j)a_{ji} \right] b_i(o_{t+1})
   $$
   得到：
   $$
   P(O|\lambda)=\sum_i\alpha_T(i)
   $$

3. 后向算法：定义 $t$ 时刻状态为 $q_i$ 的条件下，从 $t+1$ 到 $T$ 的部分观测序列为 $o_{t_1}\sim o_T$ 的概率为 **后向概率** ：
   $$
   \beta_t(i)=P(o_{t+1},...,o_T|i_t=q_i,\lambda)
   $$
   初始化后向概率：
   $$
   \beta_T(i)=1
   $$
   递推，$t=T-1,...,1$ ：
   $$
   \beta_t(i)=\sum_ja_{ij}b_j(o_{t+1})\beta_{t+1}(j)
   $$
   得到：
   $$
   P(O|\lambda)=\sum_i\pi_ib_i(o_1)\beta_1(i)
   $$

利用前向概率和后向概率的定义，可以将观测序列概率 $P(O|\lambda)$ 统一写成：
$$
P(O|\lambda)=\sum_i\sum_j\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)
$$
当 $t=T-1$ 和 $t=1$ 时，分别得到前向算法和后向算法的结果。



**学习问题** 

已知观测序列 $O=(o_1,o_2,...,o_T)$ ，估计模型 $\lambda=(A,B,\pi)$ 的参数，使得在该模型下观测序列概率 $P(O|\lambda)$ 最大。

1. 监督学习

   如果训练集中包括观测序列对应的状态序列，可以用极大似然估计法来估计模型参数。

   状态转移概率：
   $$
   a_{ij}=\frac{A_{ij}}{\sum_jA_{ij}}
   $$
   其中 $A_{ij}$ 为样本中状态 $i$ 下一时刻转移到状态 $j$ 的频数。

   观测概率：
   $$
   b_j(k)=\frac{B_{jk}}{\sum_kB_{jk}}
   $$
   其中 $B_{jk}$ 为样本中状态为 $j$ 且观测为 $k$ 的频数。

   初始状态概率 $\pi_i$ 为样本中初始状态为 $i$ 的频率。

2. 非监督学习

   如果训练集中没有观测序列对应的状态序列，那么我们把状态序列数据 $I$ 看成隐变量：
   $$
   p(O|\lambda)=\sum_IP(O|I,\lambda)P(I|\lambda)
   $$
   它的参数学习可以由 EM 算法实现。

   Baum-Welch 算法



**预测问题 / 解码问题** 

已知模型 $\lambda=(A,B,\pi)$ 和观测序列 $O=(o_1,o_2,...,o_T)$ ，求最大概率状态序列 $I=(i_1,i_2,...,i_T)$ 。

维特比算法，见 **解码算法.md** 。