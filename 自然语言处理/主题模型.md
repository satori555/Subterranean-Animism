# 主题模型

主题模型：将文档集中每篇文档的 **主题** 以概率分布的形式给出，从而通过分析一些文档抽取出它们的主题（分布），然后根据主题（分布）进行主题聚类或文本分类。同时它也是一种 **词袋模型** ，词与词之间没有先后顺序关系。

此外，一篇文档可以包含多个主题，文档中每个词都由其中的一个主题生成。

## PLSA

PLSA (Probabilistic Latent Semantic Analysis) 是一种概率图模型，阐述文本的生成过程。

假设随机变量 $d$、$w$  和 $z$ 分别表示文档、词项和主题，其中 $d$ 和 $w$ 是可以观测到的变量，$z$ 是无法直接观测的隐变量。

文档-主题分布 $p(z_k|d_i)$：给定文档 $d_i$ 的主题为 $z_k$ 的概率。

主题-词项分布 $p(w_j|z_k)$：主题为 $z_k$ 的条件下词项为 $w_j$ 的概率。

##### PLSA 文档生成过程

+ 依据概率 $p(d_i)$ 选择一个文档 $d_i$ 
+ 依据概率 $p(z_k|d_i)$ 选择一个主题 $z_k$ 
+ 依据概率 $p(w_j|z_k)$ 生成一个词项 $w_j$ 

观测变量 $(d_i,w_j)$ 的联合分布为：
$$
\begin{align}
p(d_i,w_j)
&= p(d_i)p(w_j|d_i) \\
&= p(d_i)\sum_{k=1}^K p(w_j|z_k)p(z_k|d_i)
\end{align}
$$
其中 $p(w_j|z_k)$ 和 $p(z_k|d_i)$ 是待定参数，PLSA 模型基于最大似然估计和 EM 算法进行学习。



## LDA

LDA (Latent Dirichlet Allocation) 实际上是将 PLSA 中的最大似然估计推广为贝叶斯估计。

令分布参数 $p(w_j|z_k)=\phi_{kj}$ ， $p(z_k|d_i)=\theta_{ik}$ ，在 PLSA 中 $\phi_{kj}$ 和 $\theta_{ik}$ 都是确定的变量（服从类别分布或多项式分布），而 LDA 模型将这两个参数视为随机变量，并以狄利克雷（Dirichlet）分布作为参数的先验分布。

##### 共轭先验分布

如果后验概率 $p(\theta|x)$ 和先验概率 $p(\theta)$ 满足同样的分布律，那么这一对先验分布和后验分布被称为 **共轭分布 **，同时先验分布叫做似然函数的 **共轭先验分布**。

例如，观测到的数据服从 **二项分布**，参数的先验分布和后验分布都是 Beta 分布，即 Beta 分布是二项分布的共轭概率先验分布。

类似的，**狄利克雷分布** 分布是 **多项式分布** 的共轭先验概率分布。



##### LDA 文档生成过程

+ 从狄利克雷分布 $\alpha$ 中抽样生成文档 $i$ 的主题分布 $\theta_i$ 
+ 从主题分布 $\theta_i$ 中抽样生成文档 $i$ 的第 $j$ 个词的主题 $z_{ij}$ 
+ 从狄利克雷分布 $\beta$ 中抽样生成主题 $z_{ij}$ 对应的词项分布 $\phi_{z_{ij}}$ 
+ 从词项的多项式分布 $\phi_{z_{ij}}$ 中抽样最终生成词项 $w_{ij}$ 

对比 PLSA 模型，LDA 为主题分布和词项分布加了两个狄利克雷先验，两者的差别正是频率派与贝叶斯派思想的差别。



##### Gibbs采样（Gibbs sampling）

LDA 模型难以精确地学习和推断，最简单和常用的方法是使用 Gibbs 采样。假设目标分布为 $p(x)$ ，Gibbs采样每次固定 $x$ 的一个维度 $x^i$，根据其他维度 $x^{\neg i}$ 的取值来推断该维度的分布
$$
p(x^i|x^{\neg i})=\frac{p(x^i,x^{\neg i})}{p(x^{\neg i})}
$$
并且生成该维度的样本。



##### LDA 学习过程

+ 遍历所有文档中的每个词，随机分配一个主题

+ 对每个文档 $d_i$ ：

  + 遍历 $d_i$ 中的每个词 $w_j$ 

    + 统计 $p(z_k|d_i)$ ：文档 $d_i$ 中，主题为 $z_k$ 的词的比例

    + 统计 $p(w_j|z_k)$ ：主题 $z_k$ 中，词项 $w_j$出现的比例

    + 按照概率 $p(z_k|d_i)*p(w_j|z_k)$ 给词项 $w_j$ 分配一个新的主题

+ 重复足够多次后，得到聚类结果。



##### 参考：

[1] Introduction to Latent Dirichlet Allocation
http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/

[2] 通俗理解LDA主题模型_网络_结构之法 算法之道-CSDN博客
https://blog.csdn.net/v_JULY_v/article/details/41209515

